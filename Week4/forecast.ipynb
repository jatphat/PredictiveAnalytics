{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting\n",
    "\n",
    "Source: https://github.com/gxercavins/time-series/tree/master\n",
    "\n",
    "The best model is selected for use in the final `forecast.ipynb` file, used to predict the up-coming week results. Week 5 predictions are written to a results.xlsx file and shown below.\n",
    "\n",
    "For context, the prediction results with the corresponding confidence interval (default 95 %) are also appended to the latest samples in the following graph.\n",
    "\n",
    "**Next steps**\n",
    "These results could possibly be improved by leveraging a more complex SARIMA model. For computational reasons, it was not feasible to explore higher-order parameter combinations. However, the best performing triplets are some of the most complex ones so this could lead me to believe there is room for improvement. Also, we can plot the model fit components from the integrated diagnostics tool:\n",
    "\n",
    "Briefly, whilst the residuals (top-left) resemble white noise and the correlogram (bottom-right) shows no correlation with lagged samples, the quantile distribution (bottom-left) is clearly not linear and the histogram (top-right) is far from a normal distribution. The latter two conditions hint at the possibility of obtaining a better fit, too.\n",
    "\n",
    "Also, gaining access to a larger database would mean being able to fit yearly seasonality which would require more computing resources. For clearer insights we would need more context and information about data source. If we had actual dates we could join it with a weather dataset and expect higher number of orders when the weather is not permitting.\n",
    "\n",
    "This example was intended for an interview process (input data has been appropiately modified) so the way to evaluate the model was using test data which is not provided here. Consider splitting the input data into 3 weeks training + 1 week test if needed. Some changes would be needed for a final report, such as disallowing negative forecasted values for the confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "xl = pd.ExcelFile('input_data.xlsx')\n",
    "\n",
    "data = {sheet_name: xl.parse(sheet_name) for sheet_name in xl.sheet_names}\n",
    "\n",
    "res = []\n",
    "\n",
    "for name in xl.sheet_names:\n",
    "    mylist = map(list, zip(*data[name].values))\n",
    "    aux = list(it.chain(*mylist))\n",
    "    del aux[:24]\n",
    "    res.append(aux)\n",
    "\n",
    "res = list(it.chain(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3818.95\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.3928      0.029     13.711      0.000       0.337       0.449\n",
      "ma.L1         -0.9896      0.017    -58.104      0.000      -1.023      -0.956\n",
      "ar.S.L168     -0.4395      0.020    -22.298      0.000      -0.478      -0.401\n",
      "sigma2      5239.8803    184.709     28.368      0.000    4877.858    5601.903\n",
      "==============================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of endogenous variable must be larger the the number of lags used in the model and the number of observations burned in the log-likelihood calculation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(results\u001b[38;5;241m.\u001b[39maic,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39msummary()\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_diagnostics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib64/python3.8/site-packages/statsmodels/tsa/statespace/mlemodel.py:4613\u001b[0m, in \u001b[0;36mMLEResults.plot_diagnostics\u001b[0;34m(self, variable, lags, fig, figsize, truncate_endog_names, auto_ylims, bartlett_confint, acf_kwargs)\u001b[0m\n\u001b[1;32m   4608\u001b[0m resid \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m   4609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_results\u001b[38;5;241m.\u001b[39mstandardized_forecasts_error[variable, d:],\n\u001b[1;32m   4610\u001b[0m     index\u001b[38;5;241m=\u001b[39mix)\n\u001b[1;32m   4612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resid\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m(d, lags):\n\u001b[0;32m-> 4613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of endogenous variable must be larger the the number \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof lags used in the model and the number of observations \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4616\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mburned in the log-likelihood calculation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4617\u001b[0m     )\n\u001b[1;32m   4619\u001b[0m \u001b[38;5;66;03m# Top-left: residuals vs time\u001b[39;00m\n\u001b[1;32m   4620\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m221\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Length of endogenous variable must be larger the the number of lags used in the model and the number of observations burned in the log-likelihood calculation."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train Seasonal ARIMA model\n",
    "mod = sm.tsa.statespace.SARIMAX(res,\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(1, 1, 0, 168),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "\n",
    "print(round(results.aic,2))\n",
    "print(results.summary().tables[1])\n",
    "results.plot_diagnostics(figsize=(15, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast one week ahead in future\n",
    "pred_uc = results.get_forecast(steps=168)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "\n",
    "plt.plot(pred_uc.predicted_mean)\n",
    "# plt.plot(res[-168:], color='red') # compare with previous week\n",
    "plt.xlabel('Hour Number')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.title('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel\n",
    "rows = range(0,24)\n",
    "cols = ['HOURS', 'MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']\n",
    "\n",
    "df = pd.DataFrame(columns=cols,\n",
    "                  index=rows)\n",
    "df['HOURS'] = rows\n",
    "\n",
    "pred_uc.predicted_mean = pred_uc.predicted_mean.astype(int)\n",
    "fc = [pred_uc.predicted_mean[i:i + 24] for i in range(0, len(pred_uc.predicted_mean), 24)]\n",
    "\n",
    "for i in enumerate(fc):\n",
    "    df[cols[i[0] + 1]] = i[1]\n",
    "\n",
    "df.to_excel('results.xlsx', sheet_name='W5', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot LAST_N_SAMPLES and prediction\n",
    "LAST_N_SAMPLES = 50\n",
    "\n",
    "pred_ci = pred_uc.conf_int()\n",
    "\n",
    "X_obs = range(0, 672)\n",
    "X_pred = range(672, 840)\n",
    "\n",
    "plt.plot(X_obs[-LAST_N_SAMPLES:], res[-LAST_N_SAMPLES:], label='observed')\n",
    "plt.plot(X_pred[:168], pred_uc.predicted_mean[:168], label='Forecast', alpha=.7)\n",
    "\n",
    "plt.fill_between(X_pred,\n",
    "                pred_ci[:, 0],\n",
    "                pred_ci[:, 1], color='k', alpha=.2)\n",
    "\n",
    "plt.xlabel('Hour Number')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.title('Last Orders and Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last observed value as first predicted one to avoid gap in graph\n",
    "\n",
    "X_pred = range(671, 840) # predicted range will start one sample before\n",
    "\n",
    "pred_uc.predicted_mean = np.insert(pred_uc.predicted_mean, 0, res[-1], axis=0) # we insert the value\n",
    "\n",
    "plt.plot(X_obs[-LAST_N_SAMPLES:], res[-LAST_N_SAMPLES:], label='observed')\n",
    "plt.plot(X_pred[:168], pred_uc.predicted_mean[:168], label='Forecast', alpha=.7)\n",
    "\n",
    "plt.fill_between(X_pred[1:], # now we fill confidence interval starting at sample index 1\n",
    "                pred_ci[:, 0],\n",
    "                pred_ci[:, 1], color='k', alpha=.2)\n",
    "\n",
    "plt.xlabel('Hour Number')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.title('Last Orders and Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
