{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model\n",
    "\n",
    "Source:\n",
    "\n",
    "ning.oreilly.com/library/view/machine-learning-for/9781119682363/c04.xhtml#head-2-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pmdarima in /home/mjack6/.local/lib/python3.8/site-packages (2.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/site-packages (from pmdarima) (1.3.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (0.29.21)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (1.22.3)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (1.6.0)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib64/python3.8/site-packages (from pmdarima) (0.14.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/site-packages (from pmdarima) (1.26.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.8/site-packages (from pmdarima) (51.1.2)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/site-packages (from pmdarima) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/site-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.19->pmdarima) (2020.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.19->pmdarima) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn>=0.22->pmdarima) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/mjack6/.local/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib64/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mjack6/.local/lib/python3.8/site-packages (from matplotlib) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib64/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib64/python3.8/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib64/python3.8/site-packages (from matplotlib) (8.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/local/lib64/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib64/python3.8/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **ARMA method** consists of two parts:\n",
    "\n",
    "- An autoregression\n",
    "- A moving average model\n",
    "\n",
    "Compared with the autoregressive and moving average models, ARMA models provide the most efficient linear model of stationary time series, since they are capable of modeling the unknown process with the minimum number of parameters (Zhang et al. 2015).\n",
    "\n",
    "In particular, ARMA models are used to describe weekly stationary stochastic time series in terms of two polynomials. The first of these polynomials is for autoregression, the second for the moving average. Often this method is referred to as the ARMA(p,q) model, in which:\n",
    "\n",
    "- p stands for the order of the autoregressive polynomial, and\n",
    "- q stands for the order of the moving average polynomial.\n",
    "\n",
    "Here we will see how to simulate time series from AR(p), MA(q), and ARMA(p,q) processes as well as fit time series models to data based on insights gathered from the ACF and PACF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoregressive integrated moving average (ARIMA)** models are considered a development of the simpler autoregressive moving average (ARMA) models and include the notion of integration.\n",
    "\n",
    "The main differences between ARMA and ARIMA methods are the notions of integration and differencing. An ARMA model is a stationary model, and it works very well with stationary time series.\n",
    "\n",
    "ARIMA models have three main components, denoted as p, d, q; \n",
    "\n",
    "- p stands for the number of lag variables included in the ARIMA model, also called the lag order.\n",
    "- d stands for the number of times that the raw values in a time series data set are differenced, also called the degree of differencing.\n",
    "- q denotes the magnitude of the moving average window, also called the order of moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at an extension of the ARIMA model in Python, called SARIMAX, which stands for seasonal autoregressive integrated moving average with exogenous factors. \n",
    "\n",
    "Data scientists usually apply SARIMAX when they have to deal with time series data sets that have seasonal cycles. \n",
    "\n",
    "SARIMAX models support seasonality and exogenous factors.\n",
    "\n",
    "SARIMAX requires another set of p, d, and q arguments for the seasonality aspect as well as a parameter called s, which is the periodicity of the seasonal cycle in your time series data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Date  Hour  load      T\n",
      "0  1/1/04     1   NaN  37.33\n",
      "1  1/1/04     2   NaN  37.67\n",
      "2  1/1/04     3   NaN  37.00\n",
      "3  1/1/04     4   NaN  36.33\n",
      "4  1/1/04     5   NaN  36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58134/1349270763.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Date  Hour    load      T\n",
      "2004-01-01 01:00:00 2004-01-01     1     NaN  37.33\n",
      "2004-01-01 02:00:00 2004-01-01     2     NaN  37.67\n",
      "2004-01-01 03:00:00 2004-01-01     3     NaN  37.00\n",
      "2004-01-01 04:00:00 2004-01-01     4     NaN  36.33\n",
      "2004-01-01 05:00:00 2004-01-01     5     NaN  36.00\n",
      "...                        ...   ...     ...    ...\n",
      "2014-12-31 20:00:00 2014-12-31    20  4012.0  18.00\n",
      "2014-12-31 21:00:00 2014-12-31    21  3856.0  16.67\n",
      "2014-12-31 22:00:00 2014-12-31    22  3671.0  17.00\n",
      "2014-12-31 23:00:00 2014-12-31    23  3499.0  15.33\n",
      "2015-01-01 00:00:00 2014-12-31    24  3345.0  15.33\n",
      "\n",
      "[96432 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96432, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data set\n",
    "df = pd.read_csv('data/GEFCom2014-E.csv')\n",
    "print(df.head())\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['DateTime'] = df.apply(lambda row: row['Date'] + pd.Timedelta(hours=row['Hour']), axis=1)\n",
    "df.set_index('DateTime', inplace=True)\n",
    "df = df.rename_axis(None)\n",
    "print(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (95000,)\n",
      "Test data shape:  (1432,)\n",
      "                         T\n",
      "2004-01-01 01:00:00  37.33\n",
      "2004-01-01 02:00:00  37.67\n",
      "2004-01-01 03:00:00  37.00\n",
      "2004-01-01 04:00:00  36.33\n",
      "2004-01-01 05:00:00  36.00\n",
      "                         T\n",
      "2014-11-02 09:00:00  36.33\n",
      "2014-11-02 10:00:00  36.67\n",
      "2014-11-02 11:00:00  36.67\n",
      "2014-11-02 12:00:00  37.00\n",
      "2014-11-02 13:00:00  37.33\n"
     ]
    }
   ],
   "source": [
    "train = df['T'].iloc[:95000]\n",
    "test = df['T'].iloc[95000:]\n",
    "print('Train data shape: ', train.shape)\n",
    "print('Test data shape: ', test.shape)\n",
    "train = train.to_frame()\n",
    "test = test.to_frame()\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-11-02 09:00:00</th>\n",
       "      <td>0.472435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 10:00:00</th>\n",
       "      <td>0.475391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 11:00:00</th>\n",
       "      <td>0.475391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 12:00:00</th>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-02 13:00:00</th>\n",
       "      <td>0.481130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            T\n",
       "2014-11-02 09:00:00  0.472435\n",
       "2014-11-02 10:00:00  0.475391\n",
       "2014-11-02 11:00:00  0.475391\n",
       "2014-11-02 12:00:00  0.478261\n",
       "2014-11-02 13:00:00  0.481130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale train data to be in range (0, 1)\n",
    "scaler = MinMaxScaler()\n",
    "train['T'] = scaler.fit_transform(train)\n",
    "train.head()\n",
    " \n",
    "# Scale test data to be in range (0, 1)\n",
    "test['T'] = scaler.transform(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting horizon: 3 hours\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of steps to forecast ahead\n",
    "HORIZON = 3\n",
    "print('Forecasting horizon:', HORIZON, 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order and seasonal order for the SARIMAX model\n",
    "order = (4, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/usr/local/lib64/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                                  T   No. Observations:                95000\n",
      "Model:             SARIMAX(4, 1, 0)x(1, 1, 0, 24)   Log Likelihood              290121.522\n",
      "Date:                            Wed, 29 Jan 2025   AIC                        -580231.044\n",
      "Time:                                    14:07:52   BIC                        -580174.276\n",
      "Sample:                                01-01-2004   HQIC                       -580213.776\n",
      "                                     - 11-02-2014                                         \n",
      "Covariance Type:                              opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.2787      0.003    108.275      0.000       0.274       0.284\n",
      "ar.L2          0.1628      0.003     53.429      0.000       0.157       0.169\n",
      "ar.L3          0.0318      0.003     10.338      0.000       0.026       0.038\n",
      "ar.L4         -0.0175      0.003     -5.670      0.000      -0.024      -0.011\n",
      "ar.S.L24      -0.4387      0.002   -195.335      0.000      -0.443      -0.434\n",
      "sigma2         0.0001   4.29e-07    302.685      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  61.55   Jarque-Bera (JB):             14112.52\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.92   Skew:                            -0.06\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         4.88\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the SARIMAX model\n",
    "model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    " \n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation:\n",
    "# Create a test data point for each HORIZON step\n",
    "test_shifted = test.copy()\n",
    " \n",
    "for t in range(1, HORIZON):\n",
    "    test_shifted['T+'+str(t)] = test_shifted['T'].shift(-t, freq='H')\n",
    "    \n",
    "test_shifted = test_shifted.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make predictions on the test data and use a simpler model (by specifying a different order and seasonal order) for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-11-02 09:00:00\n",
      "1 : predicted = [0.47806931 0.49952991 0.51475225] expected = [0.47243478260869565, 0.47539130434782617, 0.47539130434782617]\n",
      "2014-11-02 10:00:00\n",
      "2 : predicted = [0.49232    0.50633682 0.51530427] expected = [0.47539130434782617, 0.47539130434782617, 0.4782608695652174]\n",
      "2014-11-02 11:00:00\n",
      "3 : predicted = [0.48541104 0.49067928 0.49579837] expected = [0.47539130434782617, 0.4782608695652174, 0.48113043478260875]\n",
      "2014-11-02 12:00:00\n",
      "4 : predicted = [0.47802851 0.48140483 0.47747334] expected = [0.4782608695652174, 0.48113043478260875, 0.4869565217391304]\n",
      "2014-11-02 13:00:00\n",
      "5 : predicted = [0.48172161 0.47784227 0.47838743] expected = [0.48113043478260875, 0.4869565217391304, 0.49852173913043474]\n",
      "2014-11-02 14:00:00\n",
      "6 : predicted = [0.47709964 0.47754671 0.47098292] expected = [0.4869565217391304, 0.49852173913043474, 0.5014782608695653]\n",
      "2014-11-02 15:00:00\n",
      "7 : predicted = [0.48984456 0.4849518  0.48090806] expected = [0.49852173913043474, 0.5014782608695653, 0.5043478260869565]\n",
      "2014-11-02 16:00:00\n",
      "8 : predicted = [0.49622115 0.49412712 0.48404919] expected = [0.5014782608695653, 0.5043478260869565, 0.5043478260869565]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.04050D+00    |proj g|=  1.66766D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6      4     16      1     0     0   2.390D-02  -3.054D+00\n",
      "  F =  -3.0539107573303670     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.92014-11-02 17:00:00\n",
      "9 : predicted = [0.50034568 0.49104507 0.48232542] expected = [0.5043478260869565, 0.5043478260869565, 0.5043478260869565]\n",
      "2014-11-02 18:00:00\n",
      "10 : predicted = [0.49626551 0.4883802  0.47991985] expected = [0.5043478260869565, 0.5043478260869565, 0.5014782608695653]\n",
      "2014-11-02 19:00:00\n",
      "11 : predicted = [0.49834058 0.49135826 0.48731601] expected = [0.5043478260869565, 0.5014782608695653, 0.49852173913043474]\n",
      "2014-11-02 20:00:00\n",
      "12 : predicted = [0.49923412 0.49661641 0.49910792] expected = [0.5014782608695653, 0.49852173913043474, 0.4956521739130435]\n",
      "2014-11-02 21:00:00\n",
      "13 : predicted = [0.49945664 0.50243752 0.4972956 ] expected = [0.49852173913043474, 0.4956521739130435, 0.4869565217391304]\n",
      "2014-11-02 22:00:00\n",
      "14 : predicted = [0.50127528 0.49591394 0.48898755] expected = [0.4956521739130435, 0.4869565217391304, 0.48408695652173916]\n",
      "2014-11-02 23:00:00\n",
      "15 : predicted = [0.48872362 0.48055397 0.4789194 ] expected = [0.4869565217391304, 0.48408695652173916, 0.47243478260869565]\n",
      "2014-11-03 00:00:00\n",
      "16 : predicted = [0.47826191 0.47626358 0.47203167] expected = [0.48408695652173916, 0.47243478260869565, 0.4608695652173913]\n",
      "2014-11-03 01:00:00\n",
      "17 : predicted = [0.48358488 0.48059136 0.47388311] expected = [0.47243478260869565, 0.4608695652173913, 0.4521739130434783]\n",
      "2014-11-03 02:00:00\n",
      "18 : predicted = [0.46670941 0.45804855 0.45567231] expected = [0.4608695652173913, 0.4521739130434783, 0.44930434782608697]\n",
      "2014-11-03 03:00:00\n",
      "19 : predicted = [0.45032302 0.44668157 0.44279413] expected = [0.4521739130434783, 0.44930434782608697, 0.4521739130434783]\n",
      "2014-11-03 04:00:00\n",
      "20 : predicted = [0.44913354 0.44574746 0.45029828] expected = [0.44930434782608697, 0.4521739130434783, 0.44930434782608697]\n",
      "2014-11-03 05:00:00\n",
      "21 : predicted = [0.44596217 0.45054447 0.45043205] expected = [0.4521739130434783, 0.44930434782608697, 0.44634782608695656]\n",
      "2014-11-03 06:00:00\n",
      "22 : predicted = [0.45859369 0.45977091 0.46249036] expected = [0.44930434782608697, 0.44634782608695656, 0.44634782608695656]\n",
      "2014-11-03 07:00:00\n",
      "23 : predicted = [0.44803787 0.44884961 0.44923806] expected = [0.44634782608695656, 0.44634782608695656, 0.4695652173913044]\n",
      "2014-11-03 08:00:00\n",
      "24 : predicted = [0.44671818 0.4467054  0.45651679] expected = [0.44634782608695656, 0.4695652173913044, 0.49278260869565216]\n",
      "2014-11-03 09:00:00\n",
      "25 : predicted = [0.44624692 0.45624693 0.46235323] expected = [0.4695652173913044, 0.49278260869565216, 0.5304347826086957]\n",
      "2014-11-03 10:00:00\n",
      "26 : predicted = [0.4858278  0.4970288  0.49679951] expected = [0.49278260869565216, 0.5304347826086957, 0.5536521739130436]\n",
      "2014-11-03 11:00:00\n",
      "27 : predicted = [0.50568601 0.50675154 0.51140049] expected = [0.5304347826086957, 0.5536521739130436, 0.5739130434782609]\n",
      "2014-11-03 12:00:00\n",
      "28 : predicted = [0.53770374 0.54759861 0.55002333] expected = [0.5536521739130436, 0.5739130434782609, 0.5854782608695652]\n",
      "2014-11-03 13:00:00\n",
      "29 : predicted = [0.56656745 0.57158895 0.58068743] expected = [0.5739130434782609, 0.5854782608695652, 0.591304347826087]\n",
      "2014-11-03 14:00:00\n",
      "30 : predicted = [0.58081719 0.59128937 0.59104718] expected = [0.5854782608695652, 0.591304347826087, 0.5941739130434782]\n",
      "2014-11-03 15:00:00\n",
      "31 : predicted = [0.59766627 0.5987586  0.59951851] expected = [0.591304347826087, 0.5941739130434782, 0.5797391304347826]\n",
      "2014-11-03 16:00:00\n",
      "32 : predicted = [0.59045626 0.5898141  0.58624254] expected = [0.5941739130434782, 0.5797391304347826, 0.5536521739130436]\n",
      "2014-11-03 17:00:00\n",
      "33 : predicted = [0.59438249 0.59153315 0.58935381] expected = [0.5797391304347826, 0.5536521739130436, 0.5478260869565218]\n",
      "2014-11-03 18:00:00\n",
      "34 : predicted = [0.57319879 0.56783008 0.56386713] expected = [0.5536521739130436, 0.5478260869565218, 0.5159130434782608]\n",
      "2014-11-03 19:00:00\n",
      "35 : predicted = [0.54330957 0.53511769 0.53098903] expected = [0.5478260869565218, 0.5159130434782608, 0.49278260869565216]\n",
      "2014-11-03 20:00:00\n",
      "36 : predicted = [0.54090763 0.53781123 0.53528288] expected = [0.5159130434782608, 0.49278260869565216, 0.49278260869565216]\n",
      "2014-11-03 21:00:00\n",
      "37 : predicted = [0.50694598 0.50011666 0.49436807] expected = [0.49278260869565216, 0.49278260869565216, 0.47243478260869565]\n",
      "2014-11-03 22:00:00\n",
      "38 : predicted = [0.48255279 0.47425827 0.47174731] expected = [0.49278260869565216, 0.47243478260869565, 0.4695652173913044]\n",
      "2014-11-03 23:00:00\n",
      "39 : predicted = [0.48700137 0.4863046  0.47938161] expected = [0.47243478260869565, 0.4695652173913044, 0.4434782608695652]\n",
      "2014-11-04 00:00:00\n",
      "40 : predicted = [0.46824004 0.45826798 0.45041725] expected = [0.4695652173913044, 0.4434782608695652, 0.42895652173913046]\n",
      "2014-11-04 01:00:00\n",
      "41 : predicted = [0.4599955  0.45245307 0.44431315] expected = [0.4434782608695652, 0.42895652173913046, 0.4145217391304348]\n",
      "2014-11-04 02:00:00\n",
      "42 : predicted = [0.431739   0.42002782 0.41519966] expected = [0.42895652173913046, 0.4145217391304348, 0.42026086956521735]\n",
      "2014-11-04 03:00:00\n",
      "43 : predicted = [0.4173369  0.41249468 0.41195173] expected = [0.4145217391304348, 0.42026086956521735, 0.42895652173913046]\n",
      "2014-11-04 04:00:00\n",
      "44 : predicted = [0.4090068  0.40796571 0.40566556] expected = [0.42026086956521735, 0.42895652173913046, 0.44634782608695656]\n",
      "2014-11-04 05:00:00\n",
      "45 : predicted = [0.42170026 0.42169901 0.42063673] expected = [0.42895652173913046, 0.44634782608695656, 0.46373913043478265]\n",
      "2014-11-04 06:00:00\n",
      "46 : predicted = [0.43030826 0.43030897 0.42984179] expected = [0.44634782608695656, 0.46373913043478265, 0.46669565217391307]\n",
      "2014-11-04 07:00:00\n",
      "47 : predicted = [0.45017921 0.4525092  0.46600596] expected = [0.46373913043478265, 0.46669565217391307, 0.49852173913043474]\n",
      "2014-11-04 08:00:00\n",
      "48 : predicted = [0.47015113 0.48652903 0.50309085] expected = [0.46669565217391307, 0.49852173913043474, 0.5275652173913044]\n",
      "2014-11-04 09:00:00\n",
      "49 : predicted = [0.48199966 0.49769684 0.51934363] expected = [0.49852173913043474, 0.5275652173913044, 0.5593913043478261]\n",
      "2014-11-04 10:00:00\n",
      "50 : predicted = [0.51848194 0.54385697 0.56001311] expected = [0.5275652173913044, 0.5593913043478261, 0.5941739130434782]\n",
      "2014-11-04 11:00:00\n",
      "51 : predicted = [0.55555198 0.57385704 0.58856867] expected = [0.5593913043478261, 0.5941739130434782, 0.6145217391304348]\n",
      "2014-11-04 12:00:00\n",
      "52 : predicted = [0.57859991 0.59407906 0.6045913 ] expected = [0.5941739130434782, 0.6145217391304348, 0.6232173913043478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.8/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-11-04 13:00:00\n",
      "53 : predicted = [0.61360816 0.62750561 0.63812576] expected = [0.6145217391304348, 0.6232173913043478, 0.6347826086956522]\n",
      "2014-11-04 14:00:00\n",
      "54 : predicted = [0.62866576 0.63949529 0.64381271] expected = [0.6232173913043478, 0.6347826086956522, 0.6347826086956522]\n",
      "2014-11-04 15:00:00\n",
      "55 : predicted = [0.6326513 0.6357827 0.629184 ] expected = [0.6347826086956522, 0.6347826086956522, 0.6289565217391304]\n",
      "2014-11-04 16:00:00\n",
      "56 : predicted = [0.6384536  0.63233155 0.61803837] expected = [0.6347826086956522, 0.6289565217391304, 0.6260869565217392]\n",
      "2014-11-04 17:00:00\n",
      "57 : predicted = [0.62766913 0.61240307 0.6089501 ] expected = [0.6289565217391304, 0.6260869565217392, 0.6232173913043478]\n",
      "2014-11-04 18:00:00\n",
      "58 : predicted = [0.61418225 0.6110252  0.59191924] expected = [0.6260869565217392, 0.6232173913043478, 0.6232173913043478]\n",
      "2014-11-04 19:00:00\n",
      "59 : predicted = [0.62596086 0.60947899 0.59641362] expected = [0.6232173913043478, 0.6232173913043478, 0.6145217391304348]\n",
      "2014-11-04 20:00:00\n",
      "60 : predicted = [0.60604915 0.59240119 0.59154921] expected = [0.6232173913043478, 0.6145217391304348, 0.6058260869565217]\n",
      "2014-11-04 21:00:00\n",
      "61 : predicted = [0.61371612 0.61670942 0.60331236] expected = [0.6145217391304348, 0.6058260869565217, 0.6058260869565217]\n",
      "2014-11-04 22:00:00\n",
      "62 : predicted = [0.61754231 0.604301   0.60257607] expected = [0.6058260869565217, 0.6058260869565217, 0.6]\n",
      "2014-11-04 23:00:00\n",
      "63 : predicted = [0.58962501 0.58538376 0.56524488] expected = [0.6058260869565217, 0.6, 0.5941739130434782]\n",
      "2014-11-05 00:00:00\n",
      "64 : predicted = [0.60558423 0.58889284 0.57681851] expected = [0.6, 0.5941739130434782, 0.5884347826086956]\n",
      "2014-11-05 01:00:00\n",
      "65 : predicted = [0.58192478 0.56866314 0.55701543] expected = [0.5941739130434782, 0.5884347826086956, 0.5710434782608697]\n",
      "2014-11-05 02:00:00\n",
      "66 : predicted = [0.58393213 0.57491067 0.57794375] expected = [0.5884347826086956, 0.5710434782608697, 0.5478260869565218]\n",
      "2014-11-05 03:00:00\n",
      "67 : predicted = [0.58056063 0.5845554  0.59176844] expected = [0.5710434782608697, 0.5478260869565218, 0.5362608695652175]\n",
      "2014-11-05 04:00:00\n",
      "68 : predicted = [0.57288376 0.57810773 0.58634373] expected = [0.5478260869565218, 0.5362608695652175, 0.5536521739130436]\n",
      "2014-11-05 05:00:00\n",
      "69 : predicted = [0.5470151  0.54973163 0.55560408] expected = [0.5362608695652175, 0.5536521739130436, 0.5623478260869565]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This pro"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-11-05 06:00:00\n",
      "70 : predicted = [0.53635759 0.53990144 0.53906323] expected = [0.5536521739130436, 0.5623478260869565, 0.5652173913043479]\n",
      "2014-11-05 07:00:00\n",
      "71 : predicted = [0.56146978 0.56437383 0.59257191] expected = [0.5623478260869565, 0.5652173913043479, 0.5797391304347826]\n",
      "2014-11-05 08:00:00\n",
      "72 : predicted = [0.56552932 0.59395371 0.62075586] expected = [0.5652173913043479, 0.5797391304347826, 0.6058260869565217]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.8/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions on the test data\n",
    "training_window = 720\n",
    " \n",
    "train_ts = train['T']\n",
    "test_ts = test_shifted\n",
    " \n",
    "history = [x for x in train_ts]\n",
    "history = history[(-training_window):]\n",
    " \n",
    "predictions = []\n",
    " \n",
    "# Let's user simpler model\n",
    "order = (2, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)\n",
    " \n",
    "for t in range(test_ts.shape[0]):\n",
    "    model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(steps = HORIZON)\n",
    "    predictions.append(yhat)\n",
    "    obs = list(test_ts.iloc[t])\n",
    "    # move the training window\n",
    "    history.append(obs[0])\n",
    "    history.pop(0)\n",
    "    print(test_ts.index[t])\n",
    "    print(t+1, ': predicted =', yhat, 'expected =', obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to actual temperature\n",
    "eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])\n",
    "eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]\n",
    "eval_df = pd.melt(eval_df, id_vars='timestamp', \n",
    "value_name='prediction', var_name='h')\n",
    "eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()\n",
    "eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean absolute percentage error (MAPE)\n",
    "if(HORIZON> 1):\n",
    "    eval_df['APE'] = (eval_df['prediction'] - \n",
    "        eval_df['actual']).abs() / eval_df['actual']\n",
    "    print(eval_df.groupby('h')['APE'].mean())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print one-step forecast MAPE\n",
    "print('One step forecast MAPE: ', (mean_absolute_percentage_error(eval_df[eval_df['h'] \n",
    "== 't+1']['prediction'], \n",
    "eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')\n",
    " \n",
    "# Print multi-step forecast MAPE\n",
    "print('Multi-step forecast MAPE: ', \n",
    "mean_absolute_percentage_error(eval_df['prediction'], eval_df['actual'])*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
