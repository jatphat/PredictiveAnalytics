{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use XGBoost for Time-Series Forecasting?\n",
    "\n",
    "Source: \n",
    "Nitika Sharma, How to Use XGBoost for Time-Series Forecasting?\n",
    "https://www.analyticsvidhya.com/blog/2024/01/xgboost-for-time-series-forecasting/\n",
    "\n",
    "Raghav Agrawal, Time series Forecasting: Complete Tutorial | Part-1\n",
    "https://www.analyticsvidhya.com/blog/2021/07/time-series-forecasting-complete-tutorial-part-1/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Methods for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data: \n",
    "#import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "df = pd.read_csv(\"Electric_Production.csv\", header=0, index_col=0)\n",
    "plt.plot(df[1:50][\"Value\"])\n",
    "plt.xticks(rotation=30)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Moving Average method\n",
    "rollingseries = df[1:50].rolling(window=5)\n",
    "rollingmean = rollingseries.mean() #we can compute any statistical measure\n",
    "#print(rollingmean.head(10))\n",
    "rollingmean.plot(color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Simple Exponential Smoothing\n",
    "data = df[1:50]\n",
    "fit1 = SimpleExpSmoothing(data).fit(smoothing_level=0.2, optimized=False)\n",
    "fit2 = SimpleExpSmoothing(data).fit(smoothing_level=0.8, optimized=False)\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(df[1:50], marker='o', color=\"black\")\n",
    "plt.plot(fit1.fittedvalues, marker=\"o\", color=\"b\")\n",
    "plt.plot(fit2.fittedvalues, marker=\"o\", color=\"r\")\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Holt method for exponential smoothing\n",
    "fit1 = Holt(data).fit()  #linear trend\n",
    "fit2 = Holt(data, exponential=True).fit()  #exponential trend\n",
    "plt.plot(data, marker='o', color='black')\n",
    "plt.plot(fit1.fittedvalues, marker='o', color='b')\n",
    "plt.plot(fit2.fittedvalues, marker='o', color='r')\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition and stationarity check practicals\n",
    "\n",
    "# Step 1: Load dataset\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "DrugSalesData = pd.read_csv('TimeSeries.csv', parse_dates=['Date'], index_col='Date')\n",
    "DrugSalesData.reset_index(inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize': (10,6)})\n",
    "plt.plot(DrugSalesData['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Decomposition of time-series data\n",
    "\n",
    "# Additive Decomposition\n",
    "add_result = seasonal_decompose(DrugSalesData['Value'], model='additive',period=1)\n",
    "# Multiplicative Decomposition \n",
    "mul_result = seasonal_decompose(DrugSalesData['Value'], model='multiplicative',period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result.plot().suptitle('nAdditive Decompose', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_add = pd.concat([add_result.seasonal, add_result.trend, add_result.resid, add_result.observed], axis=1)\n",
    "new_df_add.columns = ['seasoanilty', 'trend', 'residual', 'actual_values']\n",
    "new_df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ADfuller test for stationary\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adfuller_result = adfuller(DrugSalesData.Value.values, autolag='AIC')\n",
    "print(f'ADF Statistic: {adfuller_result[0]}')\n",
    "print(f'p-value: {adfuller_result[1]}')\n",
    "for key, value in adfuller_result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor for Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "df = pd.read_csv(\"Electric_Production.csv\", header=0, index_col=0)\n",
    "plt.plot(df[1:50][\"Value\"])\n",
    "plt.xticks(rotation=30)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lag features for time-series data\n",
    "\n",
    "def create_lag_features(data, lag_steps=1):\n",
    "\n",
    "    for i in range(1, lag_steps + 1):\n",
    "\n",
    "        data[f'lag_{i}'] = data['target'].shift(i)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Applying lag feature creation to the dataset\n",
    "\n",
    "lagged_data = create_lag_features(original_data, lag_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating rolling mean for time-series data\n",
    "\n",
    "def create_rolling_mean(data, window_size=3):\n",
    "\n",
    "    data['rolling_mean'] = data['target'].rolling(window=window_size).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Applying rolling mean to the dataset\n",
    "\n",
    "rolled_data = create_rolling_mean(original_data, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Fourier transformation for capturing seasonality\n",
    "\n",
    "from scipy.fft import fft\n",
    "\n",
    "def apply_fourier_transform(data):\n",
    "\n",
    "    values = data['target'].values\n",
    "\n",
    "    fourier_transform = fft(values)\n",
    "\n",
    "    data['fourier_transform'] = np.abs(fourier_transform)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Applying Fourier transformation to the dataset\n",
    "\n",
    "fourier_data = apply_fourier_transform(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting time-series data into training and testing sets\n",
    "\n",
    "train_size = int(len(data) * 0.8)\n",
    "\n",
    "train_data, test_data = data[:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using grid search\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "\n",
    "    'max_depth': [3, 5, 7],\n",
    "\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBRegressor(), param_grid, cv=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "xgb_model = XGBRegressor(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the XGBoost model\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
